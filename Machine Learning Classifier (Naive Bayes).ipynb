{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a machine learning classifier using the Naive Bayes Classifier\n",
    "\n",
    "### The Naive Bayes classifier \n",
    "\n",
    "#### In machine learning, naïve Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naïve) independence assumptions between the features. They are among the simplest Bayesian network models. \n",
    "\n",
    "Example: classify whether a given person is a male or a female based on the measured features. The features include height, weight, and foot size.\n",
    "\n",
    "As a reminder to self: Bayesian Statistics use a prior probability in addition to new data to update probability.  The alternative would be a frequentist perspective where probability does not change given new data.    \n",
    "\n",
    "### Bayes\n",
    "#### P(A|B) = P(B|A)P(A) / P(B)\n",
    "\n",
    "#### P(H|D) = P(D|H)P(H) / P(D)\n",
    "\n",
    "• The prior P(H) is the probability that H is true before the data is considered.\n",
    "\n",
    "• The posterior P(H | D) is the probability that H is true after the data is considered.\n",
    "\n",
    "• The likelihood P(D | H) is the evidence about H provided by the data D.\n",
    "\n",
    "• P(D) is the total probability of the data taking into account all possible hypotheses.\n",
    "\n",
    "\n",
    "#### Bayesian inference\n",
    "\n",
    "• uses probabilities for both hypotheses and data.\n",
    "\n",
    "• depends on the prior and likelihood of observed data.\n",
    "\n",
    "• requires one to know or construct a ‘subjective prior’.\n",
    "\n",
    "• dominated statistical practice before the 20th century.\n",
    "\n",
    "• may be computationally intensive due to integration over many parameters.\n",
    "\n",
    "#### Frequentist inference (NHST)\n",
    "\n",
    "• never uses or gives the probability of a hypothesis (no prior or posterior).\n",
    "\n",
    "• depends on the likelihood P(D | H)) for both observed and unobserved data.\n",
    "\n",
    "• does not require a prior.\n",
    "\n",
    "• dominated statistical practice during the 20th century.\n",
    "\n",
    "• tends to be less computationally intensive\n",
    "\n",
    "\n",
    "\n",
    "Frequentist measures like p-values and confidence intervals continue to dominate research,\n",
    "especially in the life sciences. However, in the current era of powerful computers and\n",
    "big data, Bayesian methods have undergone an enormous renaissance in fields like machine learning and genetics. There are now a number of large, ongoing clinical trials using\n",
    "Bayesian protocols, something that would have been hard to imagine a generation ago.\n",
    "While professional divisions remain, the consensus forming among top statisticians is that\n",
    "the most effective approaches to complex problems often draw on the best insights from\n",
    "both schools working in concert.\n",
    "\n",
    "Learn more:  https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading20.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organize our data\n",
    "label_names = data['target_names']\n",
    "labels = data['target']\n",
    "feature_names = data['feature_names']\n",
    "features = data['data']\n",
    "list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "0\n",
      "mean radius\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    }
   ],
   "source": [
    "# Look at our data\n",
    "print(label_names)\n",
    "print(labels[0])\n",
    "print(feature_names[0])\n",
    "print(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(feature_names) # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training and Test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split our data\n",
    "train, test, train_labels, test_labels = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.33,  # 33% of the data will be set aside to test accuracy of our classifier\n",
    "                                                          random_state=42) # use randomstate to create reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB # the Naive Bayes classification algorithm is good for binary classification tasks\n",
    "\n",
    "# Initialize our classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train our classifier\n",
    "model = gnb.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "preds = gnb.predict(test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent of accurate predictions:  94.14893617021278\n"
     ]
    }
   ],
   "source": [
    "# Time to evaluate the accuary of our model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Evaluate accuracy (94.15% of predictions are accurate)\n",
    "print('percent of accurate predictions: ',accuracy_score(test_labels, preds)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full script\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Organize our data\n",
    "label_names = data['target_names']\n",
    "labels = data['target']\n",
    "feature_names = data['feature_names']\n",
    "features = data['data']\n",
    "\n",
    "# Look at our data\n",
    "print(label_names)\n",
    "print('Class label = ', labels[0])\n",
    "print(feature_names)\n",
    "print(features[0])\n",
    "\n",
    "# Split our data\n",
    "train, test, train_labels, test_labels = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.33,\n",
    "                                                          random_state=42)\n",
    "\n",
    "# Initialize our classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train our classifier\n",
    "model = gnb.fit(train, train_labels)\n",
    "\n",
    "# Make predictions\n",
    "preds = gnb.predict(test)\n",
    "print(preds)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
